{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf4710c-4315-4a51-b6eb-1788551b2232",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615e291f-643b-4989-9f34-aa466b63c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10108\\112516450.py:9: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully! Shape: (1000098, 52)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path construction (use raw string or forward slashes)\n",
    "file_path = r'C:\\Users\\user\\Desktop\\insurance-risk-analytics\\notebooks\\data\\Insurance_dataset.csv'  # Add .csv\n",
    "\n",
    "# Verify file exists\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully! Shape:\", df.shape)\n",
    "else:\n",
    "    print(\"File not found. Check:\")\n",
    "    print(\"- File exists at path\")\n",
    "    print(\"- Correct extension (.csv/.parquet/.xlsx)\")\n",
    "    print(\"- No typos in path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ce8801-feba-4e8e-8692-7add8ad4683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TransactionMonth'] = pd.to_datetime(\n",
    "    df['TransactionMonth'], \n",
    "    format='%m/%d/%Y %I:%M:%S %p',\n",
    "    errors='coerce'\n",
    ")\n",
    "df['Transaction_Year'] = df['TransactionMonth'].dt.year\n",
    "df['Transaction_Month'] = df['TransactionMonth'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127b1544-2727-4ff1-9384-c5575b3241e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop rows with missing TotalClaims if needed\n",
    "df = df[df['TotalPremium'].notnull()]\n",
    "\n",
    "# Create target for claim classification\n",
    "df['HasClaim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "\n",
    "# Fill missing numeric columns with median\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "# Fill categorical columns with 'Missing'\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "df[cat_cols] = df[cat_cols].fillna('Missing')\n",
    "\n",
    "# Feature engineering\n",
    "df['VehicleAge'] = df['Transaction_Year'] - df['RegistrationYear']\n",
    "df['IsNewVehicle'] = df['NewVehicle'].map({'Y': 1, 'N': 0})\n",
    "df['VehicleAge'] = df['VehicleAge'].clip(lower=0)\n",
    "\n",
    "# Drop columns not needed\n",
    "drop_cols = ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'VehicleIntroDate']\n",
    "df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# One-hot encode low-cardinality categoricals\n",
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44394650-28c7-47b4-a9b6-e8c5206be4ef",
   "metadata": {},
   "source": [
    "### Split Data for Severity & Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82929f8c-dd1e-41e4-be98-4a47dca7e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Severity: Only rows where TotalClaims > 0 ---\n",
    "severity_df = df[df['TotalClaims'] > 0]\n",
    "X_severity = severity_df.drop(['TotalClaims'], axis=1)\n",
    "y_severity = severity_df['TotalClaims']\n",
    "\n",
    "# --- Classification: All rows ---\n",
    "X_class = df.drop(['TotalClaims', 'HasClaim'], axis=1)\n",
    "y_class = df['HasClaim']\n",
    "\n",
    "# Train-test splits\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_severity, y_severity, test_size=0.2, random_state=42)\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6a12c-1702-425c-8b6d-a4f07bb285ae",
   "metadata": {},
   "source": [
    "### Regression (Severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4daac1-0b47-4c5f-b04b-5012a2a758b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "models_reg = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_reg.items():\n",
    "    model.fit(X_train_reg, y_train_reg)\n",
    "    preds = model.predict(X_test_reg)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_reg, preds))\n",
    "    r2 = r2_score(y_test_reg, preds)\n",
    "    print(f\"{name}: RMSE = {rmse:.2f}, RÂ² = {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda41a97-1c34-485f-a191-d3c96928f003",
   "metadata": {},
   "source": [
    "### Classification (HasClaim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3f153-7f91-492c-b1fe-393522298ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "models_cls = {\n",
    "    'Logistic': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_cls.items():\n",
    "    model.fit(X_train_cls, y_train_cls)\n",
    "    preds = model.predict(X_test_cls)\n",
    "    proba = model.predict_proba(X_test_cls)[:, 1]\n",
    "    print(f\"\\n{name}:\\n{classification_report(y_test_cls, preds)}\")\n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_test_cls, proba):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a780b-3c85-468b-aadb-266c7c5220ff",
   "metadata": {},
   "source": [
    "### SHAP Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3a34c-8477-477c-a3e7-fa60ea2d8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# For regression\n",
    "reg_best = models_reg['XGBoost']\n",
    "explainer_reg = shap.Explainer(reg_best)\n",
    "shap_values_reg = explainer_reg(X_test_reg)\n",
    "\n",
    "shap.summary_plot(shap_values_reg, X_test_reg)\n",
    "\n",
    "# For classification\n",
    "cls_best = models_cls['XGBoost']\n",
    "explainer_cls = shap.Explainer(cls_best)\n",
    "shap_values_cls = explainer_cls(X_test_cls)\n",
    "\n",
    "shap.summary_plot(shap_values_cls, X_test_cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e0d47-e7b0-4906-a7d0-9a6b6fd12e98",
   "metadata": {},
   "source": [
    "### Risk-Based Premium Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c7bd9-4c33-4f48-87b6-8d82909efa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-based premium estimate\n",
    "claim_prob = cls_best.predict_proba(X_class)[:, 1]\n",
    "claim_severity = reg_best.predict(X_class)\n",
    "\n",
    "df['RiskBasedPremium'] = (claim_prob * claim_severity) + 1000  # Add loading/margin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028468d-c569-45b9-9ccf-a225ef98b074",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25521aff-094a-485f-b95d-b0b157990166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TotalPremium', 'RiskBasedPremium', 'TotalClaims', 'HasClaim']].head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
